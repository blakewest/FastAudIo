{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.core import *\n",
    "from fastai.io import *\n",
    "from fastai.dataloader import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.learner import *\n",
    "from fastai.models.resnet import *\n",
    "import os\n",
    "from audio_dataset import *\n",
    "from audio_transforms import *\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import audioread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/audioset')\n",
    "TRN_PATH = PATH/'train_joined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.read_csv(PATH/'train_segments_cl.csv', sep=' ', usecols=[0,3])\n",
    "val = pd.read_csv(PATH/'eval_segments_cl.csv', sep=' ', usecols=[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indices = pd.read_csv(PATH/'class_labels_indices.csv', index_col='index'); label_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.rename(columns={'YTID': 'fname', 'positive_labels': 'label'}, inplace=True)\n",
    "val.rename(columns={'YTID': 'fname', 'positive_labels': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_joined = pd.concat([trn,val])\n",
    "trn_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_joined['label'] = trn_joined['label'].apply(lambda x: x.replace(',', ' ')).copy()\n",
    "trn_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = trn_joined\n",
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.to_csv(PATH/'train_joined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36217, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = pd.read_csv(PATH/'train_joined.csv'); trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = get_cv_idxs(trn.shape[0], val_pct=0.1)\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sample = trn.iloc[idxs]\n",
    "trn_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for filename in os.listdir(TRN_PATH):\n",
    " #   file = filename.rsplit('_', 1)[0]+'.wav'\n",
    "  #  os.rename(TRN_PATH/filename, TRN_PATH/file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sample.to_csv(PATH/'trn_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PPp4DcCy5v8</td>\n",
       "      <td>/m/04rlf /m/07rn7sz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7wiPgXr8zyI</td>\n",
       "      <td>/m/04rlf /m/05rwpb /m/06j64v /m/0l14gg /t/dd00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JusleurtLGs</td>\n",
       "      <td>/m/01z5f /m/068hy /m/07qf0zm /m/07r_k2n /m/0bt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5jNp0IQb5QQ</td>\n",
       "      <td>/m/04rlf /m/07qv_d5 /m/0912c9 /m/09x0r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H49R8SoFdBg</td>\n",
       "      <td>/m/07s34ls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fname                                              label\n",
       "0  PPp4DcCy5v8                                /m/04rlf /m/07rn7sz\n",
       "1  7wiPgXr8zyI  /m/04rlf /m/05rwpb /m/06j64v /m/0l14gg /t/dd00034\n",
       "2  JusleurtLGs  /m/01z5f /m/068hy /m/07qf0zm /m/07r_k2n /m/0bt...\n",
       "3  5jNp0IQb5QQ             /m/04rlf /m/07qv_d5 /m/0912c9 /m/09x0r\n",
       "4  H49R8SoFdBg                                         /m/07s34ls"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_sample = pd.read_csv(PATH/'trn_sample.csv'); trn_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_wavs = (PATH/'train_joined').glob('*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([ 0.35069]), np.array([ 0.25539]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to Sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = list(test.label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length= int(3*44100) #seconds * sample_rate\n",
    "n = 4\n",
    "\n",
    "#play sample with stats\n",
    "#length = 3*44100\n",
    "#sample = os.path.join(TRN_PATH, fnames[n])\n",
    "sample = os.path.join(TEST_PATH, test_fnames[n])\n",
    "print(test_fnames[n])\n",
    "raw = open_audio(sample)\n",
    "raw_len = len(raw)\n",
    "raw_s = adj_length(raw, length)\n",
    "#print('raw length: ', raw_len, 'sample length:', len(raw_s))\n",
    "#print('label:', trn['label'].iloc[n], 'verified:', verified[n])\n",
    "print('prediction:', test_preds[n])\n",
    "ipd.Audio(raw_s, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform():\n",
    "    \"\"\" A class that represents a transform.\n",
    "\n",
    "    All other transforms should subclass it. All subclasses should override\n",
    "    do_transform.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        tfm_y : TfmType\n",
    "            type of transform\n",
    "    \"\"\"\n",
    "    def __init__(self, tfm_y=TfmType.NO):\n",
    "        self.tfm_y=tfm_y\n",
    "        self.store = threading.local()\n",
    "\n",
    "    def set_state(self): pass\n",
    "    def __call__(self, x, y):\n",
    "        self.set_state()\n",
    "        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n",
    "                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n",
    "                else self.transform_coord(x,y))\n",
    "        return x, y\n",
    "\n",
    "    def transform_coord(self, x, y): return self.transform(x),y\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        x = self.do_transform(x,False)\n",
    "        return (x, self.do_transform(y,True)) if y is not None else x\n",
    "\n",
    "    @abstractmethod\n",
    "    def do_transform(self, x, is_y): raise NotImplementedError\n",
    "\n",
    "\n",
    "class Denormalize():\n",
    "    \"\"\" De-normalizes an image, returning it to original format.\n",
    "    \"\"\"\n",
    "    def __init__(self, m, s):\n",
    "        self.m=np.array(m, dtype=np.float32)\n",
    "        self.s=np.array(s, dtype=np.float32)\n",
    "    def __call__(self, x): return x*self.s+self.m\n",
    "\n",
    "\n",
    "class Normalize():\n",
    "    \"\"\" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image \"\"\"\n",
    "    def __init__(self, m, s): #tfm_y=TfmType.NO\n",
    "        self.m=np.array(m, dtype=np.float32)\n",
    "        self.s=np.array(s, dtype=np.float32)\n",
    "        #self.tfm_y=tfm_y\n",
    "\n",
    "    def __call__(self, x, y=None):\n",
    "        x = (x-self.m)/self.s\n",
    "        #if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n",
    "        return x,y\n",
    "\n",
    "class ChannelOrder():\n",
    "    '''\n",
    "    changes image array shape from (h, w, 3) to (3, h, w). \n",
    "    tfm_y decides the transformation done to the y element. \n",
    "    '''\n",
    "    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x = np.rollaxis(x, 2)\n",
    "        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n",
    "        #if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n",
    "        #elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n",
    "        return x,y\n",
    "\n",
    "def vocode(x,y,rate=2.0):\n",
    "    return librosa.phase_vocoder(x, rate), y\n",
    "\n",
    "def rand0(s): return random.random()*(s*2)-s\n",
    "\n",
    "def rand1(s): return int(random.random()*s)\n",
    "\n",
    "def focus_mel(aud, b, c):\n",
    "    ''' highlights audio's mel_bands'''\n",
    "    if b == 0: return aud\n",
    "    mu = np.average(aud[:b])\n",
    "    return aud[:b]+mu*c\n",
    "\n",
    "class RandomFocus_mel(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b,self.c = b,c\n",
    "        \n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand1(self.b)\n",
    "        self.store.c_rand = self.c\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        x = focus_mel(x, b, c)\n",
    "        return x\n",
    "\n",
    "def lighting(im, b, c):\n",
    "    ''' adjusts image's balance and contrast'''\n",
    "    if b==0 and c==1: return im\n",
    "    mu = np.average(im)\n",
    "    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n",
    "\n",
    "class RandomLighting(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b,self.c = b,c\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand0(self.b)\n",
    "        self.store.c_rand = rand0(self.c)\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        #if is_y and self.tfm_y != TfmType.PIXEL: return x\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        c = -1/(c-1) if c<0 else c+1\n",
    "        x = lighting(x, b, c)\n",
    "        return x\n",
    "       \n",
    "def compose(im, y, fns):\n",
    "    \"\"\" apply a collection of transformation functions fns to images\n",
    "    \"\"\"\n",
    "    for fn in fns:\n",
    "        #pdb.set_trace()\n",
    "        im, y =fn(im, y)\n",
    "    return im if y is None else (im, y)\n",
    "\n",
    "\n",
    "class Transforms():\n",
    "    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n",
    "                 tfm_y=TfmType.NO, sz_y=None):\n",
    "        if sz_y is None: sz_y = sz\n",
    "        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n",
    "        self.tfms = tfms\n",
    "        self.tfms.append(crop_tfm)\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        self.tfms.append(ChannelOrder(tfm_y))\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n",
    "    def __repr__(self): return str(self.tfms)\n",
    "\n",
    "\n",
    "def image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n",
    "              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n",
    "    \"\"\"\n",
    "    Generate a standard set of transformations\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "     normalizer :\n",
    "         image normalizing function\n",
    "     denorm :\n",
    "         image denormalizing function\n",
    "     sz :\n",
    "         size, sz_y = sz if not specified.\n",
    "     tfms :\n",
    "         iterable collection of transformation functions\n",
    "     max_zoom : float,\n",
    "         maximum zoom\n",
    "     pad : int,\n",
    "         padding on top, left, right and bottom\n",
    "     crop_type :\n",
    "         crop type\n",
    "     tfm_y :\n",
    "         y axis specific transformations\n",
    "     sz_y :\n",
    "         y size, height\n",
    "     pad_mode :\n",
    "         cv2 padding style: repeat, reflect, etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     type : ``Transforms``\n",
    "         transformer for specified image operations.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "     Transforms: the transformer object returned by this function\n",
    "    \"\"\"\n",
    "    if tfm_y is None: tfm_y=TfmType.NO\n",
    "    if tfms is None: tfms=[]\n",
    "    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n",
    "    if sz_y is None: sz_y = sz\n",
    "    if scale is None:\n",
    "        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n",
    "                 else Scale(sz, tfm_y, sz_y=sz_y)]\n",
    "    elif not is_listy(scale): scale = [scale]\n",
    "    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n",
    "    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n",
    "    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n",
    "                      tfm_y=tfm_y, sz_y=sz_y)\n",
    "\n",
    "def noop(x):\n",
    "    \"\"\"dummy function for do-nothing.\n",
    "    equivalent to: lambda x: x\"\"\"\n",
    "    return x\n",
    "\n",
    "class AudTransforms():\n",
    "    def __init__(self, tfms, normalizer, denorm):\n",
    "        #if sz_y is None: sz_y = sz\n",
    "        #self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        self.denorm,self.norm = denorm,normalizer\n",
    "        #pdb.set_trace()\n",
    "        #crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n",
    "        self.tfms = tfms\n",
    "        #self.tfms.append(crop_tfm)\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        #self.tfms.append(ChannelOrder())\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms) \n",
    "    def __repr__(self): return str(self.tfms)\n",
    "\n",
    "def audio_gen(normalizer, denorm, tfms=None):\n",
    "    if tfms is None: tfms = []\n",
    "    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n",
    "    return AudTransforms(tfms, normalizer, denorm)\n",
    "\n",
    "def aud_tfms_from_stats(stats, aug_tfms=None):\n",
    "#def tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n",
    "                    #tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n",
    "    \"\"\" Given the statistics of the training image sets, returns separate training and validation transform functions\n",
    "    \"\"\"\n",
    "    if aug_tfms is None: aug_tfms=[]\n",
    "    #tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n",
    "    tfm_norm = Normalize(*stats) if stats is not None else None\n",
    "    tfm_denorm = Denormalize(*stats) if stats is not None else None\n",
    "    #val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n",
    "    #val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n",
    "            #tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n",
    "    val_tfm = audio_gen(tfm_norm, tfm_denorm)\n",
    "    #trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n",
    "            #tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n",
    "    trn_tfm = audio_gen(tfm_norm, tfm_denorm, tfms=aug_tfms)\n",
    "    return trn_tfm, val_tfm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni, nf, ks=3, stride=1):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n",
    "\n",
    "\n",
    "def bn1(planes):\n",
    "    m = nn.BatchNorm1d(planes)\n",
    "    m.weight.data.fill_(1)\n",
    "    m.bias.data.zero_()\n",
    "    return m\n",
    "\n",
    "def bn(planes, init_zero=False):\n",
    "    m = nn.BatchNorm2d(planes)\n",
    "    m.weight.data.fill_(0 if init_zero else 1)\n",
    "    m.bias.data.zero_()\n",
    "    return m\n",
    "\n",
    "class fc1(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=2, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=ks,stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.max = nn.MaxPool2d(2, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        #return self.relu(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.max(out)\n",
    "        return out\n",
    "\n",
    "class fc2(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=ks,stride=stride)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        return self.sigmoid(out)\n",
    "        #return self.relu(out)\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super().__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        return self.lambd(x)\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv(inplanes, planes, stride=stride)\n",
    "        self.bn1 = bn(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv(planes, planes)\n",
    "        self.bn2 = bn(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        #self.max = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        #self.drop = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.downsample is not None: residual = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = residual + out\n",
    "        out = self.relu(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        #out = self.max(out)\n",
    "        #out = self.drop(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n",
    "        super().__init__()\n",
    "        self.inplanes = 64\n",
    "\n",
    "        features = [conv(1, 64, ks=7, stride=2)\n",
    "            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            , self._make_layer(block, int(64*k), layers[0])\n",
    "            , self._make_layer(block, int(128*k), layers[1], stride=2)\n",
    "            , self._make_layer(block, int(256*k), layers[2], stride=2)\n",
    "            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n",
    "        out_sz = int(512*k) * block.expansion\n",
    "\n",
    "        if vgg_head:\n",
    "            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n",
    "                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n",
    "                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n",
    "                , nn.Linear(4096, num_classes)]\n",
    "        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes), nn.Sigmoid()]\n",
    "        #else: features += [nn.MaxPool2d(2,2), fc1(out_sz, 1024), fc2(1024, 41)\n",
    "                           #, Lambda(lambda x: x.view(x.shape[0], 41, -1))\n",
    "                           #, Lambda(lambda x: torch.mean(x, dim=2))]\n",
    "        #else: features += [nn.AdaptiveMaxPool2d(3), fc1(out_sz, 1024), fc2(1024, 41), nn.AdaptiveAvgPool2d(1),\n",
    "                           #Flatten(), nn.Linear(41, num_classes)]\n",
    "\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n",
    "                bn(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)#, nn.Dropout2d(0.5))\n",
    "\n",
    "    def forward(self, x): return self.features(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from John\n",
    "def mapk_np(preds, targs, k=3):\n",
    "    preds = np.argsort(-preds, axis=1)[:, :k]\n",
    "    score = 0.0\n",
    "    for i in range(k):\n",
    "        num_hits = (preds[:, i] == targs).sum()\n",
    "        score += num_hits * (1.0 / (i+1.0))\n",
    "    score /= preds.shape[0]\n",
    "    return score\n",
    "\n",
    "def mapk(preds, targs, k=3):\n",
    "    return mapk_np(to_np(preds), to_np(targs), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B6(ni,nf):\n",
    "    return nn.Sequential(\n",
    "        conv(ni,nf), \n",
    "        bn(nf), \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2,2,padding=1))\n",
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        #self.num_classes = num_classes\n",
    "\n",
    "        features = [BasicBlock(1,16), BasicBlock(16,32), BasicBlock(32,64),\n",
    "                    BasicBlock(64,128), BasicBlock(128,256), B6(256,512),\n",
    "                    fc1(512,1024), fc2(1024,num_classes), \n",
    "                    Lambda(lambda x: x.view(x.shape[0], 41, -1)), \n",
    "                    Lambda(lambda x: torch.mean(x, dim=2))]\n",
    "        \n",
    "        self.features = nn.Sequential(*features)\n",
    "        \n",
    "    def forward(self, x): return self.features(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = aud_tfms_from_stats(stats, aug_tfms=[RandomLighting(0.5,0.5)])\n",
    "md = AudioClassifierData.from_csv(PATH, 'train_joined', PATH/'trn_sample.csv', bs=16, \n",
    "                                  tfms=tfms, suffix='.wav', test_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(): return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = resnet34()\n",
    "#m = AudioCNN(num_classes=41)\n",
    "m = MyResNet(BasicBlock, [3, 4, 6, 3], num_classes=527, vgg_head=False)\n",
    "#model = BasicModel(to_gpu(m), name='ResNet')\n",
    "opt = optim.Adam\n",
    "metrics = [accuracy, mapk]\n",
    "learn = ConvLearner.from_model_data(m, md, metrics=metrics, opt_fn=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f4297529774c0394ff282afe66de2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 144/182 [01:39<00:26,  1.44it/s, loss=0.214]"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-3, 1, wds=1e-5, cycle_len=5, use_clr_beta=(5,20,0.95,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('2d_res_1ch_hop256_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('2d_resnet_3ch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-3, 1, wds=1e-5, cycle_len=10, use_clr_beta=(5,20,0.95,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('2d_resnet_3ch_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('2d_resnet_3ch_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-4, 1, wds=1e-5, cycle_len=10, use_clr_beta=(5,20,0.95,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.('2d_resnet_3ch_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-4, 1, wds=1e-5, cycle_len=10, use_clr_beta=(5,20,0.95,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('2d_resnet_3ch_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "val_preds = learn.predict_with_targs()\n",
    "\n",
    "val_acc = accuracy_np(*val_preds)\n",
    "val_map = mapk_np(*val_preds)\n",
    "\n",
    "print(f'Val Acc: {val_acc:.3f}, Val MAP: {val_map:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_preds, y = learn.TTA(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(multi_preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(PATH/'tmp/preds11.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(sorted(trn.label.unique()))\n",
    "top_3_idx = [np.argsort(preds[i])[-3:][::-1] for i in range(len(test_fnames))]\n",
    "pred_labels = [list(classes[[top_3_idx[i]]]) for i in range(len(test_fnames))]\n",
    "preds = [\" \".join(ls) for ls in pred_labels]\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = [md.test_ds.fnames[i].split('/')[-1] for i in range(len(test_fnames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for fname in test_fnames:\n",
    "    for name in tested:\n",
    "        if name == fname:\n",
    "            idx.append(tested.index(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tested[i] for i in idx[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = [preds[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(PATH/'tmp/sub10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "deeplearning/freesound/freesound.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
