{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.core import *\n",
    "from fastai.io import *\n",
    "from fastai.dataloader import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.learner import *\n",
    "import os\n",
    "from audio_dataset import *\n",
    "from audio_transforms import *\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 2647)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y, sr = librosa.load(librosa.util.example_audio_file())\n",
    ">>> CQT = librosa.cqt(y, sr=sr, fmin=librosa.note_to_hz('A1'))\n",
    "CQT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> freqs = librosa.cqt_frequencies(CQT.shape[0],\n",
    "...                                 fmin=librosa.note_to_hz('A1'))\n",
    "freqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/librosa/core/spectrum.py:863: UserWarning: power_to_db was called on complex input so phase information will be discarded. To suppress this warning, call power_to_db(magphase(D, power=2)[0]) instead.\n",
      "  warnings.warn('power_to_db was called on complex input so phase '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -74.5256 ,  -75.03873,  -75.07569, ..., -108.56069, -108.56069, -108.56069],\n",
       "       [ -70.82057,  -70.16258,  -69.90021, ..., -107.55148, -107.55148, -107.55148],\n",
       "       [ -63.5112 ,  -63.37454,  -62.40812, ..., -106.56424, -106.56424, -106.56424],\n",
       "       ..., \n",
       "       [ -79.90505,  -79.90505,  -79.90505, ...,  -79.90505,  -79.90505,  -79.90505],\n",
       "       [ -80.09802,  -80.09802,  -80.09802, ...,  -80.09802,  -80.09802,  -80.09802],\n",
       "       [ -80.31095,  -80.31095,  -80.31095, ...,  -80.31095,  -80.31095,  -80.31095]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> perceptual_CQT = librosa.perceptual_weighting(CQT**2,\n",
    "...                                               freqs,\n",
    "...                                               ref=np.max)\n",
    ">>> perceptual_CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 2647)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptual_CQT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.3132 -0.3294 -0.0318  0.4048  0.5783\n",
       " 0.8513  0.0732  0.4767  0.3920  0.3980\n",
       "-0.1674  0.2546  0.2373 -0.4852 -0.4881\n",
       "-0.0243 -0.5040 -0.5466  0.0604 -0.6313\n",
       " 0.0409 -0.0646  0.1770 -0.4040  0.8948\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a, dim=2, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> m = nn.Sigmoid()\n",
    ">>> input = torch.randn(2)\n",
    ">>> output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  0.8414\n",
       " -0.3517\n",
       " [torch.FloatTensor of size 2], \n",
       "  0.6988\n",
       "  0.4130\n",
       " [torch.FloatTensor of size 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> # target output size of 5x7\n",
    ">>> m = nn.AdaptiveMaxPool2d((3))\n",
    ">>> input = torch.randn(64, 1, 300, 128)\n",
    ">>> output = m(input)\n",
    "output.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.MaxPool2d(2, stride=2, padding=1)\n",
    "input = torch.randn(64,1,64,300)\n",
    "output = mp(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(64,1,64,300)\n",
    "input = V(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fc2(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=ks,stride=stride)\n",
    "        self.mp =  nn.AdaptiveMaxPool2d(3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        return self.mp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn = ConvLearner.from_model_data(fc2,input)\n",
    "m = fc2(1,8)\n",
    "to_gpu(m)\n",
    "output = m(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 1, 300])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 1, 76])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp = nn.MaxPool2d(2, stride=2, padding=1)\n",
    "output = mp(output)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU(inplace)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0080e-01  3.3956e-02 -1.2168e-01  ...  -1.4699e-02 -7.2322e-02 -1.2638e-01\n",
       " 1.3621e-01 -8.2987e-02  1.5016e-01  ...  -1.2360e-01  9.3099e-03  9.0515e-02\n",
       " 1.3324e-01 -7.8864e-02  2.4596e-03  ...  -1.7639e-03 -3.4603e-02 -1.4957e-01\n",
       "                ...                   â‹±                   ...                \n",
       " 1.2222e-01 -4.2528e-02  4.5131e-02  ...  -8.8611e-02  1.9055e-01  2.2798e-01\n",
       " 4.1217e-02 -1.2219e-01 -1.5308e-01  ...   1.0378e-01  5.4179e-02 -1.2866e-02\n",
       " 5.0508e-02 -1.8143e-02 -3.2760e-01  ...   1.3317e-01  1.5288e-01 -6.8207e-02\n",
       "[torch.FloatTensor of size 64x300]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(output.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # target output size of 5x7x9\n",
    ">>> m = nn.AdaptiveAvgPool3d((5,7,9))\n",
    ">>> input = torch.randn(1, 64, 8, 9, 10)\n",
    ">>> output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5, 7, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "896 // 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
