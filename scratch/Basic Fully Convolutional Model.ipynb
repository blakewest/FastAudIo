{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from fastai import *\n",
    "from fastai.dataset import *\n",
    "from fastai.learner import *\n",
    "from fastai.text import *\n",
    "from shutil import copyfile\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/freesound')\n",
    "TRN_PATH = Path('./data/freesound/audio_train_sample')\n",
    "# TEST_PATH = Path('./data/freesound/audio_test')\n",
    "LABEL_PATH = Path('./data/freesound/train_sample.csv')\n",
    "# SAMPLE_SUBMISSION_PATH = Path('./data/freesound/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicAudioModel(nn.Module):\n",
    "    def __init__(self, num_classes, bs):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(16),\n",
    "            nn.Conv1d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(16),\n",
    "            nn.Conv1d(128, num_classes, 3),\n",
    "            Lambda(lambda tensor: torch.mean(tensor, 2, keepdim=True)),\n",
    "            Lambda(lambda tensor: tensor.view(tensor.shape[0], -1)),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "def get_trn_val_split(x, y, val_pct=0.15):\n",
    "    val_idxs = get_cv_idxs(len(x), val_pct=val_pct)\n",
    "    if isinstance(x, list):\n",
    "        return [([arr[i] for i in val_idxs], [arr[i] for i in range(len(arr)) if i not in val_idxs]) for arr in [x,y]]\n",
    "    else:\n",
    "        return split_by_idx(val_idxs, x, y)\n",
    "\n",
    "class AudioLearner(Learner):\n",
    "    def __init__(self, data, models, **kwargs):\n",
    "        super().__init__(data, models, **kwargs)\n",
    "\n",
    "    def _get_crit(self, data):\n",
    "        return F.cross_entropy\n",
    "\n",
    "def load_audio_from_df(trn_path, trn_df, sample_rate=16000):\n",
    "    return [retrieve_file(str(trn_path) + '/' + trn_df['fname'][i], sample_rate=sample_rate) for i in range(len(trn_df))]\n",
    "\n",
    "def retrieve_file(filepath, sample_rate=16000):\n",
    "    data, _ = librosa.core.load(filepath, sr=sample_rate, res_type='kaiser_fast')\n",
    "    return data\n",
    "\n",
    "def preprocess_audio(audio_files):\n",
    "    norm = librosa.util.normalize\n",
    "    return [norm(file).reshape(1, file.shape[0]) for file in audio_files]\n",
    "\n",
    "def preprocess_ys(labels, one_hot=False):\n",
    "    if isinstance(labels[0], str):\n",
    "        tok2int = {v:k for k,v in enumerate(np.unique(labels))}\n",
    "        labels = np.array([tok2int[tok] for tok in labels])\n",
    "    num_classes = len(np.unique(labels))\n",
    "    if one_hot:\n",
    "        return [one_hot(labels[i], num_classes).reshape(1, num_classes) for i in range(len(labels))]\n",
    "    else:\n",
    "        return labels\n",
    "\n",
    "class AudioModelData():\n",
    "    def __init__(self, path, trn_ds, val_ds, test_ds=None, bs=64, sample_rate=16000):\n",
    "        self.path = path\n",
    "        self.bs = bs\n",
    "        self.trn_ds, self.val_ds, self.test_ds = trn_ds, val_ds, test_ds\n",
    "        self.trn_dl = AudioDataLoader(trn_ds, bs, sampler=SortSampler(trn_ds, key=lambda x: len(trn_ds[x][0][0])))\n",
    "        self.val_dl = AudioDataLoader(val_ds, bs, sampler=SortSampler(val_ds, key=lambda x: len(val_ds[x][0][0])))\n",
    "        self.test_dl = AudioDataLoader(test_ds, bs, sampler=SortSampler(test_ds, key=lambda x: len(test_ds[x][0][0]))) if test_ds is not None else None\n",
    "        self.num_classes = self.trn_dl.dataset.get_c()\n",
    "\n",
    "    @classmethod\n",
    "    def from_path_and_dataframes(cls, trn_path, trn_df, test_path=None, test_df=None, val_path=None, val_df=None, val_pct=0.15, model_path='./', bs=64):\n",
    "        xs = load_audio_from_df(trn_path, trn_df)\n",
    "        xs = preprocess_audio(x)\n",
    "        ys = preprocess_ys(trn_df['label'])\n",
    "        if test_path is not None:\n",
    "            text_xs = load_audio_from_df(test_path, test_df)\n",
    "            text_xs = preprocess_audio(test_xs)\n",
    "        else:\n",
    "            test_x = None\n",
    "        return cls.from_array(xs, ys, test_xs, bs=bs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_array(cls, trn_x, trn_y, test_x=None, val_pct=0.15, bs=64, model_path=\"./\", **kwargs):\n",
    "        ((val_x, trn_x), (val_y, trn_y)) = get_trn_val_split(trn_x, trn_y, val_pct)\n",
    "        trn_ds = AudioDataset(trn_x, trn_y)\n",
    "        val_ds = AudioDataset(val_x, val_y)\n",
    "        test_ds = AudioDataset(test_x, test_y) if test_x is not None else None\n",
    "        return cls(model_path, trn_ds, val_ds, test_ds, bs=bs)\n",
    "\n",
    "    def get_model(self, optimizer=torch.optim.Adam):\n",
    "        basic_model = BasicAudioModel(self.num_classes, self.bs)\n",
    "        model = SingleModel(to_gpu(basic_model))\n",
    "        return AudioLearner(self, model, opt_fn=optimizer)\n",
    "\n",
    "class AudioDataLoader(DataLoader):\n",
    "    def get_batch(self, indexes):\n",
    "        batch_data = [self.dataset[i] for i in indexes]\n",
    "        x_lens = [len(item[0][0]) for item in batch_data]\n",
    "        if len(np.unique(x_lens)) > 1:\n",
    "            max_len = np.max(x_lens)\n",
    "            for i, item in enumerate(batch_data):\n",
    "                item = list(item)\n",
    "                clip_len = len(item[0][0])\n",
    "                item[0] = np.pad(item[0], ((0,0), (0, max_len-clip_len)), 'wrap')\n",
    "                batch_data[i] = tuple(item)\n",
    "        return self.np_collate(batch_data)\n",
    "\n",
    "class AudioDataset(BaseDataset):\n",
    "    def __init__(self, xs, ys, transforms=None):\n",
    "        if isinstance(ys[0], str):\n",
    "            ys = preprocess_ys(ys)\n",
    "        self.ys = ys\n",
    "        self.xs = xs\n",
    "        assert(len(xs) == len(xs)), \"Length of xs does not equal length of ys\"\n",
    "        super().__init__(transforms)\n",
    "\n",
    "    def get_x(self, i):\n",
    "        return self.xs[i]\n",
    "\n",
    "    def get_y(self, i):\n",
    "        return self.ys[i]\n",
    "\n",
    "    def get_n(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def get_sz(self):\n",
    "        return self.get_x(1).shape[0]\n",
    "\n",
    "    def get_c(self):\n",
    "        return int(np.max(self.ys) + 1)\n",
    "\n",
    "def create_sample_data(path, percent=0.1, sample_path=None, overwrite=False, labels_df=None):\n",
    "    sample_path = path + '_sample' if sample_path is None else sample_path\n",
    "    if not os.path.exists(sample_path):\n",
    "            print(\"Creating folder for the sample set...\", sample_path)\n",
    "            os.mkdir(sample_path)\n",
    "    existing_sample_files = glob(sample_path + '/*')\n",
    "    if len(existing_sample_files) > 0:\n",
    "        if not overwrite:\n",
    "            print(\"Sample already exists. Pass overwrite=True to delete and redo\")\n",
    "            return\n",
    "        else:\n",
    "            for file in existing_sample_files:\n",
    "                os.remove(file)\n",
    "    print(\"Saving a\", percent * 100, \"percent sample to\", sample_path)\n",
    "    for filepath in glob(path + '/*'):\n",
    "        if np.random.random() < percent:\n",
    "            fname = filepath.split('/')[-1]\n",
    "            copyfile(filepath, sample_path + '/' + fname)\n",
    "    if labels_df:\n",
    "        sample_fnames = [filepath.split('/')[-1] for filepath in glob(sample_path + '/*')]\n",
    "        labels_df[labels_df['fname'].isin(sample_fnames)].to_csv(path + '../train_sample.csv')\n",
    "\n",
    "def save_data(data, filename):\n",
    "    with open(filename, 'wb') as outfile:\n",
    "        pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as infile:\n",
    "        result = pickle.load(infile)\n",
    "    return result\n",
    "\n",
    "def display_sample(train, category=None):\n",
    "    sample = train[train['label'] == category].sample() if category else train.sample()\n",
    "    fname = str(TRN_PATH/sample['fname'].values[0])\n",
    "    print(sample)\n",
    "    return ipd.Audio(fname)\n",
    "\n",
    "def munge_and_save_data(trn_path, trn_df, x_filepath, y_filepath):\n",
    "    xs = load_audio_from_df(trn_path, trn_df)\n",
    "    xs = preprocess_audio(x)\n",
    "    ys = preprocess_ys(trn_df['label'])\n",
    "    save_data(xs, x_filepath)\n",
    "    save_ata(ys, y_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_and_save_data(trn_path, trn_df, x_filepath, y_filepath):\n",
    "    xs = load_audio_from_df(trn_path, trn_df)\n",
    "    xs = preprocess_audio(x)\n",
    "    ys = preprocess_ys(trn_df['label'])\n",
    "    save_data(xs, x_filepath)\n",
    "    save_ata(ys, y_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_data(DATA_PATH/'all_audio.pkl')\n",
    "y = load_data(DATA_PATH/'all_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = AudioModelData.from_array(x,y, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c717b5a531b426e9bae3579107a21e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy               \n",
      "    0      3.713458   3.713447   0.0       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.71345]), 0.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs=0.001, n_cycle=1, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
